{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map - Data Wrangling with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Project Overview\n",
    "\n",
    "To choose any area of the world in https://www.openstreetmap.org and use data wrangling techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for that part of the world. Finally, use SQL as the data schema to complete your project by storing, querying and aggregating the data.\n",
    "\n",
    "\n",
    "<img src=\"manchester_area.jpg\">\n",
    "\n",
    "Area Sampled: \n",
    "\n",
    "* Manchester and surrounding areas\n",
    "* MinLat=\"53.237\" MinLon=\"-2.588\" \n",
    "* MaxLat=\"53.672\" MaxLon=\"-1.877\"\n",
    "\n",
    "Source: https://mapzen.com/data/metro-extracts/metro/manchester_england/\n",
    "\n",
    "***\n",
    "## Data Audit\n",
    "\n",
    "Openstreet map consists of user submitted data, therefore is prone to errors. Before importing into SQL the data will be audited for accuracy and consistency, with the main focus on postal codes and street addresses.\n",
    "The main issues I noticed when investigating the data were as follows:\n",
    "\n",
    "* Abbreviated street names (Av for Avenue)\n",
    "* Incorrect and inconsistent postal codes (format)\n",
    "* Postal codes a large distance away from government data.\n",
    "\n",
    "\n",
    "### Tags\n",
    "\n",
    " ``mapparsey.py``\n",
    "\n",
    "Counts of each of the tags in the OSM data:\n",
    "```python\n",
    "{'bounds': 1,\n",
    " 'member': 31592,\n",
    " 'nd': 2039153,\n",
    " 'node': 1647945,\n",
    " 'osm': 1,\n",
    " 'relation': 2479,\n",
    " 'tag': 899132,\n",
    " 'way': 231099}\n",
    " ```\n",
    " ### Tag type count ###\n",
    " ``tags.py``\n",
    " \n",
    " Tags in OSM are represented as: ``<tag k=\"addr:country\" v=\"US\"/>``\n",
    " \n",
    " We wish to transform these into a dictionary value such as this: {\"address\": {\"country\": \"US\"}}\n",
    " \n",
    " ``tags.py`` is used to display a list of keys found in the file with the following defitions:\n",
    " \n",
    "  - **\"lower\",** for tags that contain only lowercase letters and are valid\n",
    "  - **\"lower_colon\"**, for otherwise valid tags with a colon in their names\n",
    "  - **\"problemchars\"**, for tags with problematic characters\n",
    "  - **\"other\"**, for other tags that do not fall into the other three categories.\n",
    "  \n",
    "#### Output:\n",
    "  \n",
    " ```python\n",
    " {'lower': 670084, 'lower_colon': 106435, 'other': 122610, 'problemchars': 3}\n",
    " ```\n",
    " \n",
    "#### Problem Characters consisted of the set:\n",
    " \n",
    "```python\n",
    "set(['floor_area:level -1', 'recycling:white goods', 'baby change'])\n",
    "```\n",
    " \n",
    "Which could be resolved by replace white space from characters with an underscore\n",
    " \n",
    "\n",
    "The ``others`` set consisted of a many different name patterns. Most entries had one or more letters capitalized, which was easily fixed using the str.lower() method.\n",
    "\n",
    "### Auditing street names\n",
    "``audit_streets.py``\n",
    "\n",
    "The data didn't suggest a large problem with street names, there were quite a few abbrievation issues that I didn't think of prior to the investigation, so fixed them during parsing. Examples include ln -> Lane, sq -> Square.\n",
    "A number of the street names were not capitalized correctly, this was a simple fix.\n",
    "\n",
    "A quick scan over the invalid names reveals some obviously invalid street names such as **\"Avenuehttps://streaming.media.ccc.de/33c3/\"** which have been removed.\n",
    "\n",
    "***\n",
    "\n",
    "### Auditing post codes\n",
    "``audit_postcodes.py``\n",
    "\n",
    "ref: https://stackoverflow.com/questions/164979/uk-postcode-regex-comprehensive\n",
    "\n",
    "Post codes were audited using the following regular expression\n",
    "\n",
    "\n",
    "\n",
    ">#### Explanation:\n",
    "> ``^([A-Za-z]{1,2}[0-9]{1,2}[A-Za-z]?[ ]?)([0-9]{1}[A-Za-z]{2})$ ``\n",
    "> * expect 1 or 2 a-z chars, upper or lower fine\n",
    "> * expect 1 or 2 numbers\n",
    "> * expect 0 or 1 a-z char, upper or lower fine\n",
    "> * optional space allowed\n",
    "> * expect 1 number\n",
    "> * expect 2 a-z, upper or lower fine\n",
    " \n",
    "\n",
    "Upon auditing the entire data set I found **7047 good post codes** - and **22 badly formatted postcodes** which seems like a fairly ratio of good to bad postcodes.\n",
    "\n",
    "A sample of the bad codes were as follows:\n",
    "```python \n",
    "['M34', 'M3', 'M4 1', 'M23', 'SK4', 'M1', 'SK16', 'BL5', 'BL9', 'SK5', 'SK5', 'SK5', 'BL5', 'SK8', 'M32', 'M25', 'M9', 'M15', 'M50 3SA;M50 3SB', 'CW9', 'SK5 7', 'M44'] ```\n",
    "\n",
    "I decided to dig further into the malformed postal codes.  Around ten were missing the tail of the postcode, this could be due to human error when inserting. e.g. Greenbrow Road in the dataset has a postal code of **M23**, a google search reveals the correct postal code is  **M23 2ET**.  Seeing as there were such a small amount of invalid postal codes they were dropped from the dataset.\n",
    "\n",
    "Next I obtained examined the locality of the postal codes by looking at the first two characters:\n",
    "\n",
    "```python \n",
    "{'sk': 1, 'HX': 19, 'OL': 546, 'Wa': 1, 'WA': 278, 'BL': 246, 'M9': 18, 'M5': 53, 'm2': 1, 'SK': 2775, 'M4': 146, 'M7': 20, 'M6': 17, 'M1': 1799, 'M3': 284, 'M2': 398, 'WN': 34, 'CW': 388, 'M8': 5, 'HD': 18})\n",
    "```\n",
    "\n",
    "All of these were in the area in and around Manchester so did not have to be modified.  It is worth noting that lowercase postal codes are transformed to uppercase during the final transformation.\n",
    "\n",
    "#### Gold Standard Data\n",
    "To audit postcdoes for accuracy I compared OSM postcode latitude and longituide coordinates to those found in a national dataset provided by the government.  I created a subset of the goverment data then I used the package ``gpxpy`` to compare the distance between the two sets of coordinates. Distance in KM can be worked out as follows:\n",
    "\n",
    "```python\n",
    "lat1 = float(valid_osm_postcode[postcode][0]['lat'])\n",
    "lon1 = float(valid_osm_postcode[postcode][0]['lon'])\n",
    "\n",
    "lat2 = float(valid_postcode_data[postcode]['lat'])\n",
    "lon2 = float(valid_postcode_data[postcode]['lon'])\n",
    "\n",
    "dist = gpxpy.geo.haversine_distance(lat1, lon1, lat2, lon2)\n",
    "distance[postcode] = dist / 1000\n",
    "```\n",
    "\n",
    "##### Results\n",
    "* Average distance = **0.058 km**\n",
    "* Minimum distance = **0.001 km** for the postcode **WA3 6AE**\n",
    "* Maximum distance = **0.953 km** for the postcode **M60 4EP**\n",
    "\n",
    "An average distance of 58 meters away seems like the data is *fairly* accurate. \n",
    "The largest distance postcode is nearly a kilometer away, Although postcodes can cover a large area in the UK - I think it's safe to say that has been added incorrectly.  The following post codes below were removed from the OSM dataset as they were over half a kilometer away from the gold standard dataset.\n",
    "\n",
    "|POSTCODE | DISTANCE(KM)|\n",
    "|------------------ |\n",
    "| M19 2SY |  0.525  |\n",
    "| M60 4EP |  0.952  |\n",
    "| M15 6FD |  0.689  |\n",
    "| SK5 6XD |  0.718  |\n",
    "| M17 1TD |  0.566  |\n",
    "\n",
    "\n",
    "\n",
    "### Data Cleaning Summary\n",
    "\n",
    "Overall it looks like the data for the Manchester area doesn't require too much manipulation.\n",
    "\n",
    "After auditing the data the following changes need to be made:\n",
    "* Capitalization of street names\n",
    "* Capitalization of postal codes\n",
    "* Remove postcodes with large distance difference to government dataset.\n",
    "* Conversion of abbreviated street names to proper street names\n",
    "* Removal of erroneous postal codes\n",
    "* Removal of erroneous street names\n",
    "\n",
    "## Data Overview \n",
    "\n",
    "Data was transformed into CSV files and then imported into an SQLite3 Database.  During the transformation process I had problems validating the CSV to meet the schema requirements when a node didn't have a user or userID present.  \n",
    "\n",
    "The following function looks up the default value in the schema for node or way types:\n",
    "\n",
    "```python\n",
    "def default_val(nodeval, attrib):\n",
    "\n",
    "    _type = schema.schema[nodeval]['schema'][attrib].get('coerce', \"None\")\n",
    "    if _type == int:\n",
    "        _type = 0\n",
    "    \n",
    "    return _type\n",
    "```\n",
    "\n",
    "#### File Sizes\n",
    "```\n",
    "manchester_england.osm ......... 350 MB\n",
    "osm.db ......................... 196 MB\n",
    "nodes.csv ...................... 127 MB\n",
    "nodes_tags.csv ................. 10.9 MB\n",
    "ways.csv ....................... 12.9 MB\n",
    "ways_nodes.cv .................. 46.1 MB \n",
    "ways_tags.csv .................. 19.2 MB\n",
    " \n",
    "```\n",
    "\n",
    "#### Counts\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM nodes;\n",
    "```\n",
    "NODES: 1647945\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM ways;\n",
    "```\n",
    "WAYS: 231099\n",
    "\n",
    "#### Count of McDonalds\n",
    "```SQL\n",
    "Select nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "    JOIN (Select distinct(id) FROM nodes_tags WHERE nodes_tags.value = \"restaurant\" \n",
    "    OR nodes_tags.value = \"fast_food\") as r\n",
    "ON nodes_tags.id=r.id\n",
    "WHERE nodes_tags.value like \"%mcd%\"\n",
    "```\n",
    "\n",
    "Result: 32 McDonalds\n",
    "\n",
    "#### Top Contributing Users\n",
    "\n",
    "```SQL\n",
    "SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "|Username   | Edits|\n",
    "|----------------------|\n",
    "|\"alterain\" |\t\"107657\"   |\n",
    "|\"Steeley\"\t|\"97765\"|\n",
    "|\"poshbakerloo\"|\t\"63824\"|\n",
    "|\"RobChafer\"|\t\"47438\"|\n",
    "|\"InsertUser\"|\t\"47309\"|\n",
    "|\"Chris Parker\"|\t\"46180\"|\n",
    "|\"richardwest\"|\t\"44360\"|\n",
    "|\"Nigel Greens\"|\t\"43167\"|\n",
    "|\"krispyduck\"|\t\"40536\"|\n",
    "\n",
    "\n",
    "#### Most popular restaurants\n",
    "No surprise here with Manchester and it's \"Curry Mile\", a long stretch of road full of Indian restaurants.\n",
    "```SQL\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') as r\n",
    "    ON nodes_tags.id=r.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "|Cuisine|Amount|\n",
    "|-----------------|\n",
    "|\"indian\"|\t\"68\"|\n",
    "|\"italian\"|\t\"52\"|\n",
    "|\"chinese\"|\t\"46\"|\n",
    "|\"pizza\"|\t\"19\"|\n",
    "|\"thai\"|\t\"15\"|\n",
    "|\"american\"|\t\"9\"|\n",
    "|\"asian\"|\t\"9\"|\n",
    "|\"japanese\"|\t\"9\"|\n",
    "|\"steak_house\"|\t\"9\"|\n",
    "|\"regional\"|\t\"7\"|\n",
    "\n",
    "#### Count of religious tags\n",
    "\n",
    "```SQL\n",
    "SELECT tags.value AS \"Religion\", COUNT(*) AS \"Count\" \n",
    "FROM (SELECT * FROM nodes_tags\n",
    "      UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='religion'\n",
    "GROUP BY tags.value\n",
    "ORDER BY \"Count\" DESC\n",
    "LIMIT 3;\n",
    "```\n",
    "|Religion|Amount\n",
    "|-----------|---------|\n",
    "|\"christian\"|\t\"691\"|\n",
    "|\"muslim\"|\t\"35\"|\n",
    "|\"jewish\"|\t\"13\"|\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "I've demonstrated data wrangling, cleaning and exploration skills with the OSM dataset using Python and SQL.\n",
    "\n",
    "I noticed that there is a surprisingly small number of postcodes compared to way and node data - after doing some further research I discovered nationally only 3% of postcodes are mapped in OSM.  This figure seems very low to me, perhaps a drive can be made to programically map postal code data found in official sources to  OSM? http://sk53-osm.blogspot.co.uk/2013/12/british-postcodes-on-openstreetmap.html\n",
    "\n",
    "I'm surprised at the accuracy of the postal code data that was submitted with very few failing to pass the regex test and most falling within a suitable range of the official dataset.\n",
    "\n",
    "## Other Ideas for Analysis\n",
    "\n",
    "Looking forward I understand that map data is volitile and changes frequently, to keep up with the pace of change we could consider applying a heat map to the Manchester area, highlighting zones have not been updated recently by looking at the timestamp values associate with each node or way.  By doing this areas that have not been updated recently would be targetted for a review.\n",
    "On the other hand, a negative to this is that areas may be updated unnecessarily - simply to introduce a new timestamp value which could cause inaccurate entries.\n",
    "\n",
    "Another possible solution moving forward could be creating a bot that automatically checks postal code coordinates fall within the bounds of the government data. Issues could arrise here as postal codes can cover a large area in the UK, so when do we set the maximum distance? \n",
    "These positive and negative impacts should be weighted before implementing this kind of improvement to the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References\n",
    "- Gov Data -  https://data.gov.uk/dataset/national-statistics-postcode-lookup-uk\n",
    "- OSM Data - https://mapzen.com/data/metro-extracts/metro/manchester_england/\n",
    "- Sample Project - https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n",
    "- Regex - https://stackoverflow.com/questions/164979/uk-postcode-regex-comprehensive\n",
    "- UK Postcode  Status - http://sk53-osm.blogspot.co.uk/2013/12/british-postcodes-on-openstreetmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
